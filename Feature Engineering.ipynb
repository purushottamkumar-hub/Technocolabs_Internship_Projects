{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# For regular expressions\n",
    "import re\n",
    "# For handling string\n",
    "import string\n",
    "# For performing mathematical operations\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# For missing values\n",
    "import missingno as msg\n",
    "#For datetime\n",
    "import datetime\n",
    "# For handling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>archived</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>gilded</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most of us have some family members like this....</td>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>14</td>\n",
       "      <td>YoungModern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>exmormon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But Mill's career was way better. Bentham is l...</td>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>3</td>\n",
       "      <td>RedCoatsForever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>CanadaPolitics</td>\n",
       "      <td>on</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mine uses a strait razor, and as much as i lov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>1</td>\n",
       "      <td>vhisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very fast, thank you!</td>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>2</td>\n",
       "      <td>Mastersimpson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>freedonuts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The guy is a professional, and very good at wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>6</td>\n",
       "      <td>BigGupp1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>WTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  downs  created_utc  \\\n",
       "0  Most of us have some family members like this....      0   1420070400   \n",
       "1  But Mill's career was way better. Bentham is l...      0   1420070400   \n",
       "2  Mine uses a strait razor, and as much as i lov...      0   1420070400   \n",
       "3                              Very fast, thank you!      0   1420070400   \n",
       "4  The guy is a professional, and very good at wh...      0   1420070400   \n",
       "\n",
       "   score           author distinguished  archived       subreddit  \\\n",
       "0     14      YoungModern           NaN     False        exmormon   \n",
       "1      3  RedCoatsForever           NaN     False  CanadaPolitics   \n",
       "2      1           vhisic           NaN     False   AdviceAnimals   \n",
       "3      2    Mastersimpson           NaN     False      freedonuts   \n",
       "4      6         BigGupp1           NaN     False             WTF   \n",
       "\n",
       "  author_flair_css_class author_flair_text  gilded  ups  controversiality  \\\n",
       "0                    NaN               NaN       0   14                 0   \n",
       "1                     on           Ontario       0    3                 0   \n",
       "2                    NaN               NaN       0    1                 0   \n",
       "3                    NaN               NaN       0    2                 0   \n",
       "4                    NaN               NaN       0    6                 0   \n",
       "\n",
       "  edited  \n",
       "0  False  \n",
       "1  False  \n",
       "2  False  \n",
       "3  False  \n",
       "4  False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the cleaned dataset\n",
    "\n",
    "df=pd.read_csv(\"clean_reddit_01_2015.csv\",encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove corrupt rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(num):\n",
    "    if pd.isna(num):\n",
    "        return True\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_integer(num):\n",
    "    if pd.isna(num):\n",
    "        return True\n",
    "    try:\n",
    "        int(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def valid_name(name):\n",
    "    name_regex = re.compile(r\"\\A[A-Za-z0-9][A-Za-z0-9_-]{1,20}\\Z\")\n",
    "    return bool(name_regex.match(name)) or pd.isna(name)\n",
    "\n",
    "def valid_body(body):\n",
    "    return len(body.strip()) > 0 or pd.isna(body)\n",
    "\n",
    "def is_boolean(boo):\n",
    "    return (str(boo) in ['True', 'False']) or pd.isna(boo)\n",
    "\n",
    "def valid_controversiality(controversiality):\n",
    "    return (is_number(controversiality) and float(controversiality) <= 1 and float(controversiality) >= 0) or pd.isna(controversiality)\n",
    "\n",
    "def valid_utc(utc):\n",
    "    return is_number(utc) and (len(str(utc)) == 12 or len(str(utc)) == 10) or pd.isna(utc)\n",
    "\n",
    "def valid_distinguished(distinguished):\n",
    "    return (str(distinguished) in ['nan', 'moderator', 'admin', 'special']) or pd.isna(distinguished)\n",
    "\n",
    "def valid_subreddit_type(subreddit_type):\n",
    "    return str(subreddit_type) in ['public', 'restricted', 'user'] or pd.isna(subreddit_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corrupt_rows(df):\n",
    "    corrupt_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        is_invalid_feature_info = {'author': False, 'author_flair_css_class': False, 'author_flair_text': False, 'body': False,\n",
    "       'controversiality': False, 'created_utc': False, 'distinguished': False,\n",
    "       'edited': False, 'gilded': False, 'score': False,'subreddit': False}\n",
    "        try:\n",
    "            if not valid_name(row['author']):\n",
    "                is_invalid_feature_info['author'] = True\n",
    "            if not valid_body(row['body']):\n",
    "                is_invalid_feature_info['body'] = True\n",
    "            if not valid_controversiality(row['controversiality']):\n",
    "                is_invalid_feature_info['controversiality'] = True\n",
    "            if not valid_utc(row['created_utc']):\n",
    "                is_invalid_feature_info['created_utc'] = True\n",
    "            if not valid_distinguished(row['distinguished']):\n",
    "                is_invalid_feature_info['distinguished'] = True\n",
    "            if not is_boolean(row['edited']):\n",
    "                is_invalid_feature_info['edited'] = True\n",
    "            if not is_integer(row['gilded']):\n",
    "                is_invalid_feature_info['gilded'] = True\n",
    "            if not is_integer(row['score']): \n",
    "                is_invalid_feature_info['score'] = True\n",
    "            if not valid_name(row['subreddit']): \n",
    "                is_invalid_feature_info['subreddit'] = True\n",
    "            if any(list(is_invalid_feature_info.values())):\n",
    "                corrupt_row_info = (index, is_invalid_feature_info)\n",
    "                corrupt_rows.append(corrupt_row_info)\n",
    "        except:\n",
    "            corrupt_row_info = (index, is_invalid_feature_info)\n",
    "            corrupt_rows.append(corrupt_row_info)\n",
    "    return corrupt_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_and_corrupt_df(df):\n",
    "    corrupt_row_indices = find_corrupt_rows(df)\n",
    "    print(\"Number of corrupt rows: \", len(corrupt_row_indices), \"Number of valid rows: \", str(len(df)-len(corrupt_row_indices)))\n",
    "    indices_to_drop, errors = zip(*corrupt_row_indices)\n",
    "    indices_to_drop = [int(i) for i in indices_to_drop]\n",
    "    corrupt_rows = df.iloc[indices_to_drop,:]\n",
    "    valid_rows = df.copy()\n",
    "    valid_rows = valid_rows.drop(df.index[indices_to_drop])\n",
    "    return (valid_rows, corrupt_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of corrupt rows:  8704 Number of valid rows:  178525\n"
     ]
    }
   ],
   "source": [
    "valid_train, invalid_train = get_valid_and_corrupt_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_data_types(df):\n",
    "    original_data_types = {'author': str, 'author_flair_css_class': str, 'author_flair_text': str, 'body': str,\n",
    "              'controversiality': float, 'created_utc': int, 'distinguished': str, 'edited': bool, 'gilded': int,\n",
    "                           'score': int, 'subreddit': str}\n",
    "    return df.astype(original_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_missing_values(df):\n",
    "    avg_created_utc = np.mean([time for time in df['created_utc'] if not pd.isna(time)])\n",
    "    avg_controversiality = np.mean([contro for contro in df['controversiality'] if not pd.isna(contro)])\n",
    "    replacements = {'author':'', 'author_flair_css_class':'', 'author_flair_text':'', 'body':'',\n",
    "                     'controversiality': avg_controversiality, 'created_utc':avg_created_utc,\n",
    "                    'distinguished':False, 'edited':False, 'gilded':False,\n",
    "                    'score':0, 'subreddit':''}\n",
    "    return df.fillna(value=replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = enforce_data_types(df)\n",
    "    print(\"Data types: \", df.dtypes)\n",
    "    df = fill_in_missing_values(df)\n",
    "    print(\"Columns with empty values: \", df.columns[df.isna().any()].tolist())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:  body                       object\n",
      "downs                       int64\n",
      "created_utc                 int32\n",
      "score                       int32\n",
      "author                     object\n",
      "distinguished              object\n",
      "archived                     bool\n",
      "subreddit                  object\n",
      "author_flair_css_class     object\n",
      "author_flair_text          object\n",
      "gilded                      int32\n",
      "ups                         int64\n",
      "controversiality          float64\n",
      "edited                       bool\n",
      "dtype: object\n",
      "Columns with empty values:  []\n"
     ]
    }
   ],
   "source": [
    "clean_valid_train = clean(valid_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#return the wordnet object value corresponding to the POS tag\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = str(text).lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "# clean text data\n",
    "clean_valid_train[\"body_clean\"] = clean_valid_train[\"body\"].apply(lambda x: clean_text(x))\n",
    "clean_valid_train=clean_valid_train.drop(columns=['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "def analyze_sentiments(df):\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    positive = []\n",
    "    neutral = []\n",
    "    negative = []\n",
    "    compound = []\n",
    "    for text in df['body_clean']:\n",
    "        sentiment = sentiment_analyzer.polarity_scores(str(text))\n",
    "        positive.append(sentiment['pos'])\n",
    "        neutral.append(sentiment['neu'])\n",
    "        negative.append(sentiment['neg'])\n",
    "        compound.append(sentiment['compound'])\n",
    "        if len(compound) % 500000 == 0:\n",
    "            print(len(compound), \"/\", len(df['body_clean']))\n",
    "    df['positive_sentiment'] = pd.Series(positive)\n",
    "    df['neutral_sentiment'] = pd.Series(neutral)\n",
    "    df['negative_sentiment'] = pd.Series(negative)\n",
    "    df['compound_sentiment'] = pd.Series(compound)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_train = analyze_sentiments(clean_valid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['works', 'with', 'other', 'languages']\n"
     ]
    }
   ],
   "source": [
    "#!pip install wordsegment\n",
    "import wordsegment as ws\n",
    "from wordsegment import segment\n",
    "ws.load()\n",
    "print(segment(ws.clean(\"workswithotherlanguages\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex mormon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canada politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>advice animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free donuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wtf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0        ex mormon\n",
       "1  canada politics\n",
       "2   advice animals\n",
       "3      free donuts\n",
       "4              wtf"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordsegment import load, segment\n",
    "def segmentSubreddits(frame):\n",
    "    subreddits=frame['subreddit']\n",
    "    finalsb=[]\n",
    "    ws.load()\n",
    "    for i, sb in zip(range(len(subreddits)), subreddits):\n",
    "        if i%25000 == 0:\n",
    "            print(i/25000)\n",
    "        if len(sb) != 0:\n",
    "            segmented=segment(ws.clean(sb))\n",
    "            stringsb=\"\"\n",
    "            for c in segmented:\n",
    "                stringsb+=c+\" \"\n",
    "            finalsb.append(stringsb[:-1])\n",
    "        else:\n",
    "            finalsb.append(sb)\n",
    "    return finalsb\n",
    "\n",
    "subreddits_fixed=pd.DataFrame(segmentSubreddits(engineered_train))\n",
    "subreddits_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of characters column\n",
    "engineered_train[\"nb_chars\"] = engineered_train[\"body_clean\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# add number of words column\n",
    "engineered_train[\"nb_words\"] = engineered_train[\"body_clean\"].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>archived</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>gilded</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>edited</th>\n",
       "      <th>body_clean</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>nb_chars</th>\n",
       "      <th>nb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>14</td>\n",
       "      <td>YoungModern</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>exmormon</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>family member like family like</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>3</td>\n",
       "      <td>RedCoatsForever</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>CanadaPolitics</td>\n",
       "      <td>on</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>mill's career way well bentham like joseph smi...</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>1</td>\n",
       "      <td>vhisic</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>mine use strait razor much love clipper love r...</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>106</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>2</td>\n",
       "      <td>Mastersimpson</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>freedonuts</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>fast thank</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>6</td>\n",
       "      <td>BigGupp1</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>WTF</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>guy professional good highly doubt miss often</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.1953</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   downs  created_utc  score           author distinguished  archived  \\\n",
       "0      0   1420070400     14      YoungModern           nan     False   \n",
       "1      0   1420070400      3  RedCoatsForever           nan     False   \n",
       "2      0   1420070400      1           vhisic           nan     False   \n",
       "3      0   1420070400      2    Mastersimpson           nan     False   \n",
       "4      0   1420070400      6         BigGupp1           nan     False   \n",
       "\n",
       "        subreddit author_flair_css_class author_flair_text  gilded  ups  \\\n",
       "0        exmormon                    nan               nan       0   14   \n",
       "1  CanadaPolitics                     on           Ontario       0    3   \n",
       "2   AdviceAnimals                    nan               nan       0    1   \n",
       "3      freedonuts                    nan               nan       0    2   \n",
       "4             WTF                    nan               nan       0    6   \n",
       "\n",
       "   controversiality  edited  \\\n",
       "0               0.0    True   \n",
       "1               0.0    True   \n",
       "2               0.0    True   \n",
       "3               0.0    True   \n",
       "4               0.0    True   \n",
       "\n",
       "                                          body_clean  positive_sentiment  \\\n",
       "0                     family member like family like               0.625   \n",
       "1  mill's career way well bentham like joseph smi...               0.338   \n",
       "2  mine use strait razor much love clipper love r...               0.363   \n",
       "3                                         fast thank               0.714   \n",
       "4      guy professional good highly doubt miss often               0.251   \n",
       "\n",
       "   neutral_sentiment  negative_sentiment  compound_sentiment  nb_chars  \\\n",
       "0              0.375               0.000              0.6124        30   \n",
       "1              0.662               0.000              0.5574        69   \n",
       "2              0.563               0.074              0.8481       106   \n",
       "3              0.286               0.000              0.3612        10   \n",
       "4              0.346               0.404             -0.1953        45   \n",
       "\n",
       "   nb_words  \n",
       "0         5  \n",
       "1        11  \n",
       "2        20  \n",
       "3         2  \n",
       "4         7  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178525, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_train.to_csv(\"engineered_train.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
